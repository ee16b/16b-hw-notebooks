{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6znzg0c4EQw"
   },
   "outputs": [],
   "source": [
    "# Load libraries and generate datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# This part of the code generates the 2 datasets\n",
    "# Feel free to read through it to understand how the data is generated.\n",
    "# Do not change it.\n",
    "np.random.seed(1044216)\n",
    "\n",
    "def generate_dataset(sources, n_data_points, noise_var, data_mean=[0.0, 0.0]):\n",
    "  n_sources = len(sources)\n",
    "  base_pts = np.random.randn(n_data_points,1)\n",
    "  noise_input = [noise_var[0] * np.random.randn(n_data_points,2), \\\n",
    "                 noise_var[1] * np.random.randn(n_data_points,2)]\n",
    "  data_pts = [data_mean[sx] + base_pts * sources[sx] + noise_input[sx] \\\n",
    "              for sx in range(n_sources)]\n",
    "  \n",
    "  merged_data = np.concatenate(data_pts)\n",
    "  np.random.shuffle(merged_data)\n",
    "  return merged_data\n",
    "\n",
    "# Dataset 1\n",
    "sources_1   = [np.array([[1.5, 1.5]]), np.array([[1.0, -1.0]])]\n",
    "noise_var_1 = [0.5, 0.5]\n",
    "data_mean_1 = [2*np.random.randn(), 2*np.random.randn()]\n",
    "dataset_1   = generate_dataset(sources_1, 1000, noise_var_1, data_mean_1)\n",
    "\n",
    "# Dataset 2\n",
    "sources_2   = [np.array([[1.5, 0.9]]), np.array([[0.9, 1.5]])]\n",
    "noise_var_2 = [0.2, 0.2]\n",
    "data_mean_2 = [1.5*np.random.randn(), 3.0*np.random.randn()]\n",
    "dataset_2   = generate_dataset(sources_2, 1000, noise_var_2, data_mean_2)\n",
    "\n",
    "# Dataset 3\n",
    "sources_3   = [np.array([1.0, -1.0]), np.array([1.0, -1.0])]\n",
    "noise_var_3 = [0.1, 0.1]\n",
    "data_mean_3 = [0.3, -0.3]\n",
    "dataset_3   = generate_dataset(sources_3, 1000, noise_var_3, data_mean_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rin-g7tBPKBp"
   },
   "outputs": [],
   "source": [
    "# Plot the data sets\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(dataset_1[:,0], dataset_1[:,1], alpha=0.5, color='#1f77b4')\n",
    "plt.xlabel('$\\mathregular{x_1}$')\n",
    "plt.ylabel('$\\mathregular{x_2}$')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(dataset_2[:,0], dataset_2[:,1], alpha=0.5, color='#1f77b4')\n",
    "plt.xlabel('$\\mathregular{x_1}$')\n",
    "plt.ylabel('$\\mathregular{x_2}$')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(dataset_3[:,0], dataset_3[:,1], alpha=0.5, color='#1f77b4')\n",
    "plt.xlabel('$\\mathregular{x_1}$')\n",
    "plt.ylabel('$\\mathregular{x_2}$')\n",
    "# DEBUG HELP - Print the dataset size\n",
    "# print(dataset_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8H5zgZURSCBW"
   },
   "outputs": [],
   "source": [
    "# First find the mean of the dataset and the substract it to center the data\n",
    "def demean_dataset(dataset):\n",
    "  #================ STUDENT CODE HERE =======================#\n",
    "  # Change these lines to subtract the mean from the data\n",
    "  original_data_mean = None\n",
    "  demeaned_data = None\n",
    "  new_dataset_mean = None\n",
    "  #====================== END CODE ==========================#\n",
    "  print(\"Original dataset has mean...\")\n",
    "  print(original_data_mean)\n",
    "  print(\"After mean subtraction, the mean is...\")\n",
    "  print(new_dataset_mean)\n",
    "  return demeaned_data\n",
    "\n",
    "def get_singular_value_decomp(A):\n",
    "  #================ STUDENT CODE HERE =======================#\n",
    "  # Change these lines to find the singular value decomposition \n",
    "  # using inbuilt library functions\n",
    "\n",
    "  sigma = None\n",
    "  u_vec = None\n",
    "  v_vec = None\n",
    "  #====================== END CODE ==========================#\n",
    "\n",
    "  return u_vec, sigma, v_vec\n",
    "\n",
    "def get_principal_components(u_vec, sigma, v_vec):\n",
    "  #================ STUDENT CODE HERE =======================#\n",
    "  n_data_points = u_vec.shape[0]\n",
    "\n",
    "  # Use the singular value decomposition to find the two \n",
    "  # principal components\n",
    "  w1 = None\n",
    "  PC_1 = None\n",
    "\n",
    "  w2 = None\n",
    "  PC_2 = None\n",
    "  #====================== END CODE ==========================#  \n",
    "\n",
    "  return w1, w2, PC_1, PC_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YU1PNkHb4Iy"
   },
   "outputs": [],
   "source": [
    "# Use the methods defined in the previous code block to get the principal \n",
    "# components for the two datasets\n",
    "\n",
    "def your_PCA_algorithm(dataset):\n",
    "  demeaned_data = demean_dataset(dataset)\n",
    "  u_vec, sigma, v_vec = get_singular_value_decomp(demeaned_data)\n",
    "  w1, w2, PC_1, PC_2 = get_principal_components(u_vec, sigma, v_vec)\n",
    "\n",
    "  plt.figure(figsize=(6,6))\n",
    "  plt.scatter(demeaned_data[:,0], demeaned_data[:,1], alpha=0.5, color='#1f77b4')\n",
    "  # Principal components rescaled to show them on the same scale as the data\n",
    "  plt.arrow(0, 0, w1*PC_1[0], w1*PC_1[1], width=0.1, facecolor='k')\n",
    "  plt.arrow(0, 0, w2*PC_2[0], w2*PC_2[1], width=0.1, facecolor='k')\n",
    "  plt.xlabel('$\\mathregular{x_1}$')\n",
    "  plt.ylabel('$\\mathregular{x_2}$')\n",
    "  plt.show()\n",
    "\n",
    "  print('Weight %.2f, First Principal Component: '%w1)\n",
    "  print(PC_1)\n",
    "  print('Weight %.2f, Second Principal Component: '%w2)\n",
    "  print(PC_2)\n",
    "  print()\n",
    "\n",
    "  return w1, w2, PC_1, PC_2\n",
    "\n",
    "your_PCA_algorithm(dataset_1)\n",
    "your_PCA_algorithm(dataset_2)\n",
    "your_PCA_algorithm(dataset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YbPnIyV6cES"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SVD_PCA_Implementation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}